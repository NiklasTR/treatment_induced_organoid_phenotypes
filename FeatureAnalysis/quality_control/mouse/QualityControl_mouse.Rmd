---
title: "Screen Quality Control (Mouse)"
author: "Jan Sauer"
date: "22.10.2017"
output: 
  html_document:
    toc: true
    toc_depth: 3
    number_sections: true
---

This vignette performs quality control of the mouse screen.

```{r message=FALSE, warning=FALSE, include=FALSE}
# Install and load libraries
library(PROMISE)
library(ggplot2)
library(data.table)
library(rhdf5)
library(pander)
library(caret)

# Directories and files
# config_dir = "/collab-ag-fischer/PROMISE/data-10x-4t-c-16z/configdir"
config_dir = "/local-collab-ag-fischer/PROMISE/data-10x-4t-c-16z/configdir"
# feature_dir = "/collab-ag-fischer/FeatureAnalysis/features"
feature_dir = "/Users/jansauer/Thesis/Projects/PROMISE/FeatureAnalysis/python_package/cell_line_features"
blurry_organoid_dir = "/Users/jansauer/Thesis/Projects/PROMISE/FeatureAnalysis/python_package/blurry_organoids"
source(file.path(config_dir, "watchdogConfig.R"))

# Parameters
feature_type = "organoids"
hdf5_dataset = "features_zscore_rep_organoids"
```

# Data preprocessing

The data preprocessing consists of the following steps:

* Separate objects into "organoids" (area >= 2500 pixels) and "shrapnel" (area <= 2500 pixels).
* Calculate the summary features for each of these categories of objects within a well (median / mad).
  * I decided for this summary statistic as some features may only have features within a certain range, e.g. [0, 1] for the asphericity. Even under the assumption of normally distributed variation within a well, this limitation would cause the mean to skew the summary statistic towards the middle of the interval.
* Subtract from each feature the median of the DMSO wells and divide by their standard deviation on each plate to eliminate batch effects.
* Combine plates belonging to a single cell line and calculate the z-score for each feature.

This is done in an external python script. The data and all intermediate steps are stored in the corresponding hdf5 files in the PROMISE features directory.

```{r load_data}
cell_lines = unique(substr(list.files(feature_dir, pattern = "M001"), 1, 7))
features = setNames(
  object = vector(mode="list", length=length(cell_lines)), 
  nm = cell_lines)
features_metadata = setNames(
  object = vector(mode="list", length=length(cell_lines)), 
  nm = cell_lines)
for(cell_line in cell_lines) {
  cl_feature_fn = file.path(feature_dir, sprintf("%s_averaged_features_%s.h5", cell_line, feature_type))
  features[[cell_line]] = data.frame(h5read(cl_feature_fn, hdf5_dataset))
  colnames(features[[cell_line]]) = h5read(cl_feature_fn, "feature_names")
  rownames(features[[cell_line]]) = h5read(cl_feature_fn, "well_names")
  
  features_metadata[[cell_line]] = data.frame(
    "REPLICATE" = h5read(cl_feature_fn, "replicates"),
    "CONCENTRATION" = h5read(cl_feature_fn, "concentrations"),
    "DRUG" = h5read(cl_feature_fn, "drugs"), 
    row.names = rownames(features[[cell_line]]))
}
features = do.call(rbind, features)
rownames(features) = sapply(strsplit(rownames(features), ".", fixed = TRUE), "[[", 2)
features_metadata = do.call(rbind, features_metadata)
rownames(features_metadata) = sapply(strsplit(rownames(features_metadata), ".", fixed = TRUE), "[[", 2)
```

Ensure that only wells with two replicates are kept
```{r}
rows_repid = paste0(substr(rownames(features), 1, 7), "_", substr(rownames(features), 12, 19))
valid_row_ids = names(which(table(rows_repid) == 2))
features = features[rows_repid %in% valid_row_ids, ]
features_metadata = features_metadata[rows_repid %in% valid_row_ids, ]
```

For any number of reasons, some wells may not have been processed properly. In particular, if there is no information to the total number of organoids in a well then it can be safely discarded as this feature should always be computable.
```{r}
na_rows = rownames(features)[!is.finite(features$organoids_num.of.objects)]
na_rows_repid = paste0(substr(na_rows, 1, 7), "_", substr(na_rows, 12, 19))
all_wells_repid = paste0(substr(rownames(features), 1, 7), "_", substr(rownames(features), 12, 19))
features = features[!all_wells_repid %in% na_rows_repid, ]
features_metadata = features_metadata[!all_wells_repid %in% na_rows_repid, ]
```

Due to the normalization method, features may be marked as NaN or Infinity. This can happen in particular if a feature was constant across all DMSO wells of a plate. Since the wells are already averages over all organoids within the wells, I assume that a constant feature value across all DMSO wells indicates a bad feature. As I've already removed any bad wells, I now remove all features that do not have finite values in all remaining wells.
```{r}
nanfeatures = colSums(!is.finite(as.matrix(features)))
features = features[,nanfeatures == 0]
```

The features should now all be finite
```{r}
cat("Number of NaN features:", sum(!is.finite(as.matrix(features))))
```

# Quality Control
## Blurry Wells

Some of the wells were found to be entirely blurry and are effectively unusable. These have been previously classified with a random forest classifier. The blurry wells and their replicates are filtered out.
```{r}
blurry_wells = read.table("blurry_wells_mouse.txt", stringsAsFactors = FALSE)
blurry_wells_repid = paste0(substr(blurry_wells$V1, 1, 7), "_", substr(blurry_wells$V1, 12, 19))
all_wells_repid = paste0(substr(rownames(features), 1, 7), "_", substr(rownames(features), 12, 19))
wells_to_keep = !all_wells_repid %in% blurry_wells_repid
features = features[wells_to_keep,]
features_metadata = features_metadata[wells_to_keep,]
```

## Blurry Organoids

The microscope images are projections of 3D image stacks. As a result, many organoids are not captured in focus by the microscope. A first step of quality control is remove wells (and necessarily their replicates), that do not have a sufficient number of focused organoids in the images. To ensure the image quality of a well, I require that the ratio of focused to blurry organoids is at least 50%. I also remove the replicates of these wells.
```{r}
plates = substr(rownames(features), 1, 14)
blurry_well_dat = list()
for(plate in unique(plates)) {
  blurry_well_dat[[plate]] = read.csv(
    file.path(blurry_organoid_dir, sprintf("%s_blurry_organoid_statistics.csv", plate)), 
    row.names = 1)
}
blurry_well_dat = do.call(rbind, blurry_well_dat)
rownames(blurry_well_dat) = sapply(
  strsplit(rownames(blurry_well_dat), ".", fixed = TRUE), "[[", 2)
blurry_well_dat = blurry_well_dat[rownames(features), ]
blurry_well_dat$Ratio = blurry_well_dat$Focused_Organoids / 
  (blurry_well_dat$Focused_Organoids + blurry_well_dat$Blurry_Organoids)

remove_wells = rownames(blurry_well_dat)[blurry_well_dat$Ratio < 0.5]

rw_repid = paste0(substr(remove_wells, 1, 7), "_", substr(remove_wells, 12, 19))
all_wells_repid = paste0(substr(rownames(features), 1, 7), "_", substr(rownames(features), 12, 19))
features = features[!all_wells_repid %in% rw_repid, ]
features_metadata = features_metadata[!all_wells_repid %in% rw_repid, ]
blurry_well_dat = blurry_well_dat[!all_wells_repid %in% rw_repid, ]
```

## Cell Line Quality
Normally, one would look at the z-factor, a degree of separation between positive and negative controls, for each feature to determine the assay quality. As there are no known positive controls for the mouse screen, I instead look at the z-factor for all treatments compared to the negative controls (DMSO) for a few characteristic features, the number of organoids, the total biomass, and the average organoid size. I expect that at least some of the treatments should show considerable differences to the DMSO controls in these features.

The z-factor is defined as:

$$ Z^\prime = 1 - \frac{3 \cdot (\sigma_{treatment} + \sigma_{DMSO})}{|\mu_{treatment} - \mu_{DMSO}|}$$

```{r}
treatments = unique(features_metadata$DRUG)

all_biomass_zprime = list()
all_orgsize_zprime = list()
all_orgnum_zprime = list()

for(cell_line in cell_lines) {
  biomass_zprime = setNames(
    object = vector(mode="numeric", length=length(treatments)), 
    nm = treatments)
  orgsize_zprime = setNames(
    object = vector(mode="numeric", length=length(treatments)), 
    nm = treatments)
  orgnum_zprime = setNames(
    object = vector(mode="numeric", length=length(treatments)), 
    nm = treatments)
  dmso_treatment_biomass = features[
      features_metadata$DRUG == "DMSO" & 
        substr(rownames(features), 1, 7) == cell_line,
      "Total.Biomass"]
  dmso_treatment_orgsize = features[
      features_metadata$DRUG == "DMSO" & 
        substr(rownames(features), 1, 7) == cell_line,
      "organoids_x.0.s.area_expected"]
  dmso_treatment_orgnum = features[
      features_metadata$DRUG == "DMSO" & 
        substr(rownames(features), 1, 7) == cell_line,
      "organoids_num.of.objects"]
  for(treatment in treatments) {
    biomass_treatment_feat = features[
      features_metadata$DRUG == treatment & 
        substr(rownames(features), 1, 7) == cell_line, 
      "Total.Biomass"]
    orgsize_treatment_feat = features[
      features_metadata$DRUG == treatment & 
        substr(rownames(features), 1, 7) == cell_line, 
      "organoids_x.0.s.area_expected"]
    orgnum_treatment_feat = features[
      features_metadata$DRUG == treatment & 
        substr(rownames(features), 1, 7) == cell_line, 
      "organoids_num.of.objects"]
    
    biomass_zprime[[treatment]] = imageHTS::zprime(
      dmso_treatment_biomass,  biomass_treatment_feat, method = "robust")
    orgsize_zprime[[treatment]] = imageHTS::zprime(
      dmso_treatment_orgsize,  orgsize_treatment_feat, method = "robust")
    orgnum_zprime[[treatment]] = imageHTS::zprime(
      dmso_treatment_orgnum,  orgnum_treatment_feat, method = "robust")
  }
  
  all_biomass_zprime[[cell_line]] = biomass_zprime
  all_orgsize_zprime[[cell_line]] = orgsize_zprime
  all_orgnum_zprime[[cell_line]] = orgnum_zprime
}

all_biomass_zprime_df = do.call(cbind, all_biomass_zprime)
all_biomass_zprime_df = all_biomass_zprime_df[
  rowSums(!is.finite(as.matrix(all_biomass_zprime_df))) ==  0,]
all_biomass_zprime_df = apply(all_biomass_zprime_df, 2, sort)
all_biomass_zprime_df = melt(all_biomass_zprime_df)
all_orgsize_zprime_df = do.call(cbind, all_orgsize_zprime)
all_orgsize_zprime_df = all_orgsize_zprime_df[
  rowSums(!is.finite(as.matrix(all_orgsize_zprime_df))) ==  0,]
all_orgsize_zprime_df = apply(all_orgsize_zprime_df, 2, sort)
all_orgsize_zprime_df = melt(all_orgsize_zprime_df)
all_orgnum_zprime_df = do.call(cbind, all_orgnum_zprime)
all_orgnum_zprime_df = all_orgnum_zprime_df[
  rowSums(!is.finite(as.matrix(all_orgnum_zprime_df))) ==  0,]
all_orgnum_zprime_df = apply(all_orgnum_zprime_df, 2, sort)
all_orgnum_zprime_df = melt(all_orgnum_zprime_df)

ggplotdf = data.frame(
  "Cell.Line" = all_biomass_zprime_df$Var2,
  "Total.Biomass" = all_biomass_zprime_df$value,
  "Num.Organoids" = all_orgnum_zprime_df$value,
  "Avg.Organoid.Size" = all_orgsize_zprime_df$value,
  "Treatment" = NA_real_)
ggplotdf = ggplotdf[
  is.finite(ggplotdf$Total.Biomass) & 
  is.finite(ggplotdf$Num.Organoids) &
  is.finite(ggplotdf$Avg.Organoid.Size), ]
for(cell_line in cell_lines) {
  ggplotdf[ggplotdf$Cell.Line == cell_line, "Treatment"] = 
    seq_len(table(ggplotdf$Cell.Line)[cell_line])
}
```

```{r}
ggplot(data = ggplotdf) +
  geom_line(aes(x = Treatment, y = Total.Biomass, color = Cell.Line)) + 
  coord_cartesian(ylim = c(-1, 1), xlim = c(750, 950)) + 
  ggtitle(label = "Z-Factor of the Total Biomass for the Treatments of each Cell Line")
```

```{r}
ggplot(data = ggplotdf) +
  geom_line(aes(x = Treatment, y = Num.Organoids, color = Cell.Line)) + 
  coord_cartesian(ylim = c(-1, 1), xlim = c(750, 950)) + 
  ggtitle(label = "Z-Factor of the Number of Organoids for the Treatments of each Cell Line")
```

```{r}
ggplot(data = ggplotdf) +
  geom_line(aes(x = Treatment, y = Avg.Organoid.Size, color = Cell.Line)) + 
  coord_cartesian(ylim = c(-1, 1), xlim = c(750, 950)) + 
  ggtitle(label = "Z-Factor of the Average Organoid Size for the Treatments of each Cell Line")
```

While the quality of the screen is far from ideal by this standard, all cell lines perform equally well.

## Pruning Features

Features only make sense if they are sufficiently continuous. I want to discard features that do not have sufficiently many unique values. I keep only features with more than 25% unique values across all plates.
```{r}
# neg_ctrl = features[features_metadata$DRUG == "DMSO", ]
# This rounding ensures that there are no floating point arithmetic errors that are mistaken as unique values
# neg_ctrl = round(neg_ctrl, 8)
# neg_ctrl_cl = substr(rownames(neg_ctrl), 1, 14)
# unique_vals = aggregate(neg_ctrl, list(neg_ctrl_cl), function(x) length(unique(x)) / length(x))
unique_vals = aggregate(
  features, list(substr(rownames(features), 1, 14)), 
  function(x) length(unique(x)) / length(x))
rownames(unique_vals) = unique_vals$Group.1
unique_vals$Group.1 = NULL
unique_vals_min = apply(unique_vals, 2, min)
unique_vals_min_df = data.frame(
  "Ratio.Unique.Vals" = sort(unique_vals_min, decreasing = TRUE), 
  "Features" = seq_along(unique_vals_min))
ggplot(data = unique_vals_min_df) + geom_point(aes(x = Features, y = Ratio.Unique.Vals)) + 
  ggtitle("Minimum Ratio of Unique Values for each Feature", 
          subtitle = "e.g. a 'minimum ratio' of 0.25 means all plates had a ratio of >= 25% of unique values for that feature") + 
  geom_hline(aes(yintercept = 0.25), color = "blue")

features_to_keep = names(which(unique_vals_min >= 0.25))
if(!"Total.Biomass" %in% features_to_keep)
  features_to_keep = c(features_to_keep, "Total.Biomass")
if(!"organoids_x.0.s.area_expected" %in% features_to_keep)
  features_to_keep = c(features_to_keep, "organoids_x.0.s.area_expected")
if(!"organoids_num.of.objects" %in% features_to_keep)
  features_to_keep = c(features_to_keep, "organoids_num.of.objects")
features = features[,features_to_keep]
```

## Correlation between replicates
### Cell line specfific
I look at all features now to see how well they correlate between replicates of the screen for each cell line individually

```{r}
cl_correlations = setNames(
  object = vector(mode = "list", length = length(cell_lines)), 
  nm = cell_lines
)
cl_correlations_unsorted = setNames(
  object = vector(mode = "list", length = length(cell_lines)), 
  nm = cell_lines
)
for(cell_line in cell_lines) {
  cl_features = features[substr(rownames(features), 1, 7) == cell_line, ]
  cl_features_metadata = features_metadata[substr(rownames(features_metadata), 1, 7) == cell_line, ]
  rep1 = cl_features[cl_features_metadata$REPLICATE == 1, ]
  rep2 = cl_features[cl_features_metadata$REPLICATE == 2, ]
  if(!identical(paste0(substr(rownames(rep1), 1, 7), "_", substr(rownames(rep1), 12, 19)), 
                paste0(substr(rownames(rep2), 1, 7), "_", substr(rownames(rep2), 12, 19)))) {
    warning(sprintf("Replicates for '%s' are not in the same order!", cell_line))
  }
  rep_correlations = setNames(
    object = vector(mode = "numeric", length = ncol(cl_features)), 
    nm = colnames(cl_features))
  for(feature in colnames(cl_features)) {
    rep_correlations[[feature]] = cor(
      rep1[[feature]], rep2[[feature]], 
      use = "pairwise.complete.obs")
  }
  cl_correlations_unsorted[[cell_line]] = data.frame(
    "Features" = seq_along(rep_correlations),
    "Feature.Name" = names(rep_correlations),
    "Correlations" = rep_correlations, 
    "Cell.Line" = cell_line
  )
  cl_correlations[[cell_line]] = data.frame(
    "Features" = seq_along(rep_correlations),
    "Feature.Name" = names(rep_correlations),
    "Correlations" = sort(rep_correlations, decreasing = TRUE), 
    "Cell.Line" = cell_line
  )
}

cl_correlations = do.call(rbind, cl_correlations)
cl_correlations_unsorted = do.call(rbind, cl_correlations_unsorted)
ggplot(data = cl_correlations) + geom_line(aes(x = Features, y = Correlations, color = Cell.Line)) + 
  ggtitle("Correlations between Replicates for each Individual Cell Line", 
          subtitle = "Features are sorted independently for each cell line")
```

Cell lines M001W01 and M001A03 both show very low correlations. This will become a problem during the feature selection, which requires that features correlate significantly between replicates. To complicate things even further, different features correlate strongly in each cell line. The consequence of this is that the stability selection, which relies on correlating replicates, will select far too many ($\geq 100$) features for any reasonable analysis.
```{r}
cor_w = cl_correlations_unsorted[cl_correlations_unsorted$Cell.Line == "M001W01", "Correlations"]
cor_k = cl_correlations_unsorted[cl_correlations_unsorted$Cell.Line == "M001K02", "Correlations"]
cor_a = cl_correlations_unsorted[cl_correlations_unsorted$Cell.Line == "M001A03", "Correlations"]
cor_b = cl_correlations_unsorted[cl_correlations_unsorted$Cell.Line == "M001B04", "Correlations"]
min_cor = sapply(seq_len(length(cor_w)), function(x) {
  min(cor_w[x], cor_k[x], cor_a[x], cor_b[x])})

cor_thresholds = seq(0, 1, 0.05)
num_common_features = sapply(cor_thresholds, function(ct) sum(min_cor >= ct))
ggplotdf = data.frame("Correlation" = cor_thresholds, "Features" = num_common_features)
ggplotdf = ggplotdf[ggplotdf$Features > 0, ]
ggplot(data = ggplotdf) + geom_point(aes(x = Correlation, y = Features)) + 
  scale_y_log10() + ggtitle(
    "Common Correlating Features", 
    subtitle = "Number of features that correlate with at least 'x' in each cell line individually")
```

Instead, I select features based only on their correlation with each other. I start keeping only features that correlate with at least $\rho \geq 0.25$ within all cell lines and then remove all features that correlate with at least $\rho \geq 0.9$ with another feature. This leaves a set of 32 features.
```{r}
features = features[, min_cor >= 0.25]
features_cor = cor(features, use = "pairwise.complete.obs")
features_to_remove = findCorrelation(features_cor, cutoff = 0.9, names = TRUE)
features = features[, !colnames(features) %in% features_to_remove]

features_metadata$CELL.LINE = substr(rownames(features_metadata), 1, 7)
saveRDS(object = features, file = "QC_mouse_selected_features.rds")
saveRDS(object = features_metadata, file = "QC_mouse_selected_features_metadata.rds")
```
